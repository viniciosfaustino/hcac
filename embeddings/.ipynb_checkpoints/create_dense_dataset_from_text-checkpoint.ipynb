{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "#this script should get a dataset which each row is a tuple, with the text and the label and transform it\n",
    "#in a tuple with the array of the embeddings and the label\n",
    "\n",
    "#first step should be load the previous dataset\n",
    "#then should be done some preprocessing to get the embeddings of the sentence\n",
    "#after getting all the embeddings of the sentences, the arrays should be reshaped with the maximum dimension \n",
    "\n",
    "embeddings = []\n",
    "dense_dateset = []\n",
    "max_dim = (0,0)\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "#the preprocessing step also should split the words\n",
    "def preprocessing(sentence):\n",
    "    return sentence\n",
    "\n",
    "\n",
    "#------------------------------------------------------------\n",
    "#this function should diferentiate a path to a dataset and a actual dataset array-like\n",
    "def load_dataset(dataset):\n",
    "    \n",
    "    sentences = dataset[0]\n",
    "    labels = dataset[1]\n",
    "    return sentences, labels\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "def get_embeddings(sentences, labels)\n",
    "    \n",
    "    model = KeyedVectors.load_word2vec_format('cbow_s50.txt')\n",
    "    for i,sentence in enumerate(sentences):\n",
    "        sentence = preprocessing(sentence)\n",
    "        emb = []\n",
    "        for w in sentence:    \n",
    "            emb.append(model.word_vec(str(w)))\n",
    "        emb = np.array(emb)\n",
    "        #row = [emb,label[i]]\n",
    "        embeddings.append(emb)\n",
    "        max_dim = max(max_dim, emb.shape)\n",
    "        \n",
    "    return embeddings, max_dim\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "#as long as the sentences have a different number of words and for computational purposes the shape of them must be equal\n",
    "#this function will set the default shape as the max of all the sentences, doing some zero padding to all the ones that doesn't fit the shape\n",
    "def do_padding(embeddings, max_dim, label):\n",
    "    for i,em in enumerate(embeddings):\n",
    "        if em.shape != max_dim:\n",
    "            new_row = np.zeros(max_dim[0]*max_dim[1]).reshape(max_dim)\n",
    "            new_row[0:em.shape[0],0:em.shape[1]] += em\n",
    "            embeddings[i] = new_row\n",
    "            \n",
    "        dense_dataset.append([em,labels[i]])\n",
    "    return dense_dateset\n",
    "            \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
